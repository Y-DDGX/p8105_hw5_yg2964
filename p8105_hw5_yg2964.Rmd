---
title: "p8105_hw5_yg2964"
output: github_document
date: "2024-11-14"
---

```{r setup,include=FALSE}
library(tidyverse)
library(rvest)
library(dplyr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(127)
```

### Problem 1
Function to simulate birthdays and check for duplicates
```{r}
bday_sim = function(n){
bdays = sample(1:365, size = n, replace=TRUE)

duplicate = length(unique(bdays))<n
return(duplicate)
}
```

Run simulations for group sizes 2 to 50
```{r}
sim_res =
  expand_grid(
    n = 2:50,
    iter = 1:10000
  ) |> 
  mutate(res = map_lgl(n,bday_sim)) |> 
  group_by(n) |> 
  summarize(probability = mean(res))
```

Create visualization
```{r}
sim_res |>
  ggplot(aes(x = n, y = probability)) +
  geom_line(size = 1) +    # Removed color specification to use viridis default
  labs(
    title = "Probability of Shared Birthdays by Group Size",
    x = "Number of People in Group",
    y = "Probability of Shared Birthday",
    caption = "Based on 10,000 simulations per group size"
  ) +
  scale_y_continuous(labels = scales::percent)
```
The plot clearly illustrates the famous "birthday paradox" showing the probability of shared birthdays as group size increases. The probability grows surprisingly quickly: with just 23 people, there's already a 50% chance of a shared birthday, rising to about 70% with 30 people, and exceeding 85% with 40 people. This counter-intuitive result shows how we typically underestimate the probability of birthday matches in relatively small groups. The simulation, run 10,000 times per group size, presents these findings in a clear way.

### Problem 2
Function to generate data and perform t-test
```{r}
# Create function for t-test
t_test_sim <- function(mu) {
  sample_data <- rnorm(30, mean = mu, sd = 5)
  t.test(sample_data, mu = 0) |>
    broom::tidy() |>
    select(estimate, p.value)
}
```

Generate data for mu = 0
```{r}
results_mu0 <- 
  tibble(
    mu = 0,
    iteration = 1:5000
  ) |>
  mutate(
    test_results = map(mu, t_test_sim)
  ) |>
  unnest(test_results)
```

Generate data for mu = 1 to 6
```{r}
results_mu1to6 <- 
  expand_grid(
    mu = 1:6,
    iteration = 1:5000
  ) |>
  mutate(
    test_results = map(mu, t_test_sim)
  ) |>
  unnest(test_results)
```

Combine results
```{r}
simulation_results <- bind_rows(results_mu0, results_mu1to6)
```


Plot 1: Power vs True mu
```{r}
simulation_results |>
  group_by(mu) |>
  summarize(
    power = mean(p.value < alpha)
  ) |>
  ggplot(aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power Analysis",
    x = "μ",
    y = "Power"
  )
print(simulation_results)
```

Plot 2: Average Estimates
```{r}
simulation_results |>
  group_by(mu) |>
  summarize(
    all_mean = mean(estimate),
    sig_mean = mean(estimate[p.value < alpha])
  ) |>
  ggplot() +
  geom_line(aes(x = mu, y = all_mean, color = "All")) +
  geom_line(aes(x = mu, y = sig_mean, color = "Significant")) +
  labs(
    title = "Average Estimates",
    x = "μ",
    y = "Estimate",
    color = "Samples"
  )
print(simulation_results)
```







